{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from keras import backend as K \n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.models import Sequential\n",
    "from keras import applications\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "import os.path\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('/mnt/metadata_sf.csv')\n",
    "metadata.rename(columns={'id':'image_id', 'datetaken':'date_taken'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    if os.path.exists(image_path):\n",
    "#         im = cv2.resize(cv2.imread(image_path), (224, 224)).astype(np.float32)\n",
    "#         im[:,:,0] -= 103.939\n",
    "#         im[:,:,1] -= 116.779\n",
    "#         im[:,:,2] -= 123.68\n",
    "#         im = im.transpose((2,0,1))\n",
    "#         im = np.expand_dims(im, axis=0)\n",
    "#         return im\n",
    "#     else:\n",
    "#         return None\n",
    "        img = load_img(image_path,target_size=(224,224))  # this is a PIL image\n",
    "        array = img_to_array(img)\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24624, 3, 224, 224)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['img_path'] = '/mnt/images/' + metadata['image_id'].astype(str) + '.jpg'\n",
    "metadata['img_array'] = metadata['img_path'].apply(lambda row: prepare_image(row))\n",
    "metadata = metadata[pd.notnull(metadata['img_array'])]\n",
    "\n",
    "x = np.asarray(metadata['img_array'].tolist()).reshape(len(metadata),3,224,224)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def creating_labels(x):\n",
    "    if ( 'topic' in x):\n",
    "        return x['topic']\n",
    "    elif (\"nature\" in str(x['tags_clean'])) or (\"lake\" in str(x['tags_clean'])) or (\"river\" in str(x['tags_clean'])) or (\"view\" in str(x['tags_clean'])) or (\"beach\" in str(x['tags_clean'])) or (\"flowers\" in str(x['tags_clean'])) or (\"landscape\" in str(x['tags_clean'])) or (\"waterfall\" in str(x['tags_clean'])) or (\"sunrise\" in str(x['tags_clean'])) or (\"sunset\" in str(x['tags_clean'])) or (\"water\" in str(x['tags_clean'])) or (\"nationalpark\" in str(x['tags_clean'])) or (\"alaska\" in str(x['tags_clean'])) or (\"sky\" in str(x['tags_clean'])) or (\"yosemite\" in str(x['tags_clean'])) or (\"mountains\" in str(x['tags_clean'])):\n",
    "        return 'Natural Landscape'\n",
    "    elif (\"birds\" in str(x['tags_clean'])) or (\"wild\" in str(x['tags_clean'])) or (\"wildlife\" in str(x['tags_clean'])) or (\"forest\" in str(x['tags_clean'])) or (\"animals\" in str(x['tags_clean'])) or (\"zoo\" in str(x['tags_clean'])):\n",
    "        return 'Animals & Birds'\n",
    "    elif (\"food\" in str(x['tags_clean'])) or (\"brunch\" in str(x['tags_clean'])) or (\"dinner\" in str(x['tags_clean'])) or (\"lunch\" in str(x['tags_clean'])) or (\"bar\" in str(x['tags_clean'])) or (\"restaurant\" in str(x['tags_clean'])) or (\"drinking\" in str(x['tags_clean'])) or (\"eating\" in str(x['tags_clean'])):\n",
    "        return 'Food'\n",
    "    elif (\"urban\" in str(x['tags_clean'])) or (\"shop\" in str(x['tags_clean'])) or (\"market\" in str(x['tags_clean'])) or (\"square\" in str(x['tags_clean'])) or (\"building\" in str(x['tags_clean'])) or (\"citylights\" in str(x['tags_clean'])) or (\"cars\" in str(x['tags_clean'])) or (\"traffic\" in str(x['tags_clean'])) or (\"city\" in str(x['tags_clean'])) or (\"downtown\" in str(x['tags_clean'])) or (\"sanfrancisco\" in str(x['tags_clean'])) or (\"newyork\" in str(x['tags_clean'])) or (\"newyork\" in str(x['tags_clean'])) or (\"seattle\" in str(x['tags_clean'])) or (\"sandiego\" in str(x['tags_clean'])) or (\"washington\" in str(x['tags_clean'])):\n",
    "        return 'Urban Scenes'\n",
    "    elif (\"hotel\" in str(x['tags_clean'])) or (\"home\" in str(x['tags_clean'])) or (\"interior\" in str(x['tags_clean'])):\n",
    "        return 'Interiors'\n",
    "    elif (\"us\" in str(x['tags_clean'])) or (\"people\" in str(x['tags_clean'])) or (\"group\" in str(x['tags_clean'])) or (\"friends\" in str(x['tags_clean'])):\n",
    "        return 'people'\n",
    "    else:\n",
    "        return \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urban         6491\n",
       "landscapes    5361\n",
       "wildlife      4642\n",
       "food          4615\n",
       "people        2848\n",
       "drinks         667\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['tags_clean']= metadata['tags'].str.split()\n",
    "metadata = metadata.replace(np.nan, '', regex=True)\n",
    "\n",
    "metadata['labels'] = metadata.apply(creating_labels, axis=1)\n",
    "topics = metadata['labels'].unique().tolist()\n",
    "topics = list(set(topics) - set(['Others']))\n",
    "\n",
    "metadata = metadata.loc[metadata['labels'].isin(topics)]\n",
    "metadata['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    6491\n",
       "0    5361\n",
       "4    4642\n",
       "5    4615\n",
       "1    2848\n",
       "3     667\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = d={x:i for i,x in enumerate(topics)}\n",
    "y = metadata['labels'].apply(lambda row : label_map[row])\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "num_classes = 6\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 13)\n",
    "# Transform targets to keras compatible format\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19699, 6)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/applications/inception_v3.py:367: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19699 samples, validate on 4925 samples\n",
      "Epoch 1/2\n",
      "19699/19699 [==============================] - 242s 12ms/step - loss: 1.3007 - val_loss: 0.9852\n",
      "Epoch 2/2\n",
      "19699/19699 [==============================] - 235s 12ms/step - loss: 0.9523 - val_loss: 0.9207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f165f0a6128>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit(x_train, y_train, nb_epoch=2, verbose = 1, validation_data = (x_test,y_test))\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:18: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19699 samples, validate on 4925 samples\n",
      "Epoch 1/30\n",
      "19699/19699 [==============================] - 277s 14ms/step - loss: 0.5438 - acc: 0.8105 - val_loss: 0.8036 - val_acc: 0.7334\n",
      "Epoch 2/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.5241 - acc: 0.8146 - val_loss: 0.8097 - val_acc: 0.7342\n",
      "Epoch 3/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.4937 - acc: 0.8249 - val_loss: 0.8186 - val_acc: 0.7354\n",
      "Epoch 4/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.4699 - acc: 0.8341 - val_loss: 0.8285 - val_acc: 0.7328\n",
      "Epoch 5/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.4460 - acc: 0.8420 - val_loss: 0.8392 - val_acc: 0.7334\n",
      "Epoch 6/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.4213 - acc: 0.8519 - val_loss: 0.8541 - val_acc: 0.7316\n",
      "Epoch 7/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.3986 - acc: 0.8609 - val_loss: 0.8701 - val_acc: 0.7299\n",
      "Epoch 8/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.3689 - acc: 0.8707 - val_loss: 0.8808 - val_acc: 0.7314\n",
      "Epoch 9/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.3445 - acc: 0.8799 - val_loss: 0.9035 - val_acc: 0.7291\n",
      "Epoch 10/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.3278 - acc: 0.8847 - val_loss: 0.9183 - val_acc: 0.7295\n",
      "Epoch 11/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.3053 - acc: 0.8941 - val_loss: 0.9324 - val_acc: 0.7283\n",
      "Epoch 12/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.2820 - acc: 0.9001 - val_loss: 0.9543 - val_acc: 0.7299\n",
      "Epoch 13/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.2667 - acc: 0.9070 - val_loss: 0.9716 - val_acc: 0.7295\n",
      "Epoch 14/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.2463 - acc: 0.9136 - val_loss: 1.0024 - val_acc: 0.7265\n",
      "Epoch 15/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.2307 - acc: 0.9191 - val_loss: 1.0173 - val_acc: 0.7267\n",
      "Epoch 16/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.2127 - acc: 0.9270 - val_loss: 1.0384 - val_acc: 0.7261\n",
      "Epoch 17/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.2075 - acc: 0.9284 - val_loss: 1.0489 - val_acc: 0.7275\n",
      "Epoch 18/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1964 - acc: 0.9321 - val_loss: 1.0676 - val_acc: 0.7293\n",
      "Epoch 19/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1812 - acc: 0.9380 - val_loss: 1.0859 - val_acc: 0.7279\n",
      "Epoch 20/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1722 - acc: 0.9395 - val_loss: 1.0967 - val_acc: 0.7263\n",
      "Epoch 21/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1653 - acc: 0.9433 - val_loss: 1.1176 - val_acc: 0.7239\n",
      "Epoch 22/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1638 - acc: 0.9417 - val_loss: 1.1246 - val_acc: 0.7241\n",
      "Epoch 23/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1496 - acc: 0.9487 - val_loss: 1.1392 - val_acc: 0.7271\n",
      "Epoch 24/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1440 - acc: 0.9499 - val_loss: 1.1475 - val_acc: 0.7251\n",
      "Epoch 25/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1412 - acc: 0.9505 - val_loss: 1.1658 - val_acc: 0.7243\n",
      "Epoch 26/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1326 - acc: 0.9532 - val_loss: 1.1728 - val_acc: 0.7281\n",
      "Epoch 27/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1277 - acc: 0.9559 - val_loss: 1.1869 - val_acc: 0.7259\n",
      "Epoch 28/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1289 - acc: 0.9540 - val_loss: 1.1983 - val_acc: 0.7243\n",
      "Epoch 29/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1213 - acc: 0.9561 - val_loss: 1.2040 - val_acc: 0.7279\n",
      "Epoch 30/30\n",
      "19699/19699 [==============================] - 270s 14ms/step - loss: 0.1196 - acc: 0.9580 - val_loss: 1.2083 - val_acc: 0.7277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1657c69b00>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i, layer in enumerate(base_model.layers):\n",
    "    #print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit(x_train, y_train, nb_epoch=30, verbose = 1, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('/mnt/cnn_2epoch_1210.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4925, 6), (4925, 6))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mix type of y not allowed, got types {'multilabel-indicator', 'continuous-multioutput'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-96ed846ba5d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits)\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix type of y not allowed, got types %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mys_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mlabel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mys_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix type of y not allowed, got types {'multilabel-indicator', 'continuous-multioutput'}"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
